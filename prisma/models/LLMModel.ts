import { LLMModel } from '@prisma/client';
type LLMModelOmitType = Omit<LLMModel, 'id' | 'created_at' | 'updated_at'>;

export const PRE_CONFIGURED_LLM_MODEL: LLMModelOmitType[] = [
  {
    name: 'StarCoder2-3B-Basic',
    modelName: 'starcoder2:3b',
    version: 'latest',
    description: 'StarCoder2 3B with default settings.',
    temperatureMin: 0,
    temperatureMax: 1,
    temperatureDefault: 0.7,
    top_pMin: 0,
    top_pMax: 1,
    top_pDefault: 0.9,
    top_kMin: 0,
    top_kMax: 100,
    top_kDefault: 0,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 256,
    presence_penaltyMin: -2,
    presence_penaltyMax: 2,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -2,
    frequency_penaltyMax: 2,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 2,
    repeat_penaltyDefault: 1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'StarCoder2-3B-Deterministic',
    modelName: 'starcoder2:3b',
    version: 'latest',
    description: 'StarCoder2 3B for more deterministic code generation.',
    temperatureMin: 0,
    temperatureMax: 0.2,
    temperatureDefault: 0.1,
    top_pMin: 0,
    top_pMax: 0.2,
    top_pDefault: 0.1,
    top_kMin: 0,
    top_kMax: 5,
    top_kDefault: 3,
    max_tokensMin: 1,
    max_tokensMax: 2048,
    max_tokensDefault: 512,
    presence_penaltyMin: -1,
    presence_penaltyMax: 1,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -1,
    frequency_penaltyMax: 1,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.2,
    repeat_penaltyDefault: 1.1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'StarCoder2-3B-Creative',
    modelName: 'starcoder2:3b',
    version: 'latest',
    description: 'StarCoder2 3B for more creative and varied code generation.',
    temperatureMin: 0.7,
    temperatureMax: 1,
    temperatureDefault: 0.8,
    top_pMin: 0.7,
    top_pMax: 1,
    top_pDefault: 0.95,
    top_kMin: 50,
    top_kMax: 100,
    top_kDefault: 75,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 1024,
    presence_penaltyMin: -0.5,
    presence_penaltyMax: 0.5,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -0.5,
    frequency_penaltyMax: 0.5,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.5,
    repeat_penaltyDefault: 1.2,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Gemma-2B-Basic',
    modelName: 'gemma:2b',
    version: 'latest',
    description: 'Gemma 2B with default settings.',
    temperatureMin: 0,
    temperatureMax: 1,
    temperatureDefault: 0.7,
    top_pMin: 0,
    top_pMax: 1,
    top_pDefault: 0.9,
    top_kMin: 0,
    top_kMax: 100,
    top_kDefault: 0,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 256,
    presence_penaltyMin: -2,
    presence_penaltyMax: 2,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -2,
    frequency_penaltyMax: 2,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 2,
    repeat_penaltyDefault: 1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Gemma-2B-CreativeText',
    modelName: 'gemma:2b',
    version: 'latest',
    description: 'Gemma 2B for creative text generation.',
    temperatureMin: 0.6,
    temperatureMax: 1,
    temperatureDefault: 0.8,
    top_pMin: 0.6,
    top_pMax: 1,
    top_pDefault: 0.95,
    top_kMin: 20,
    top_kMax: 100,
    top_kDefault: 50,
    max_tokensMin: 1,
    max_tokensMax: 2048,
    max_tokensDefault: 512,
    presence_penaltyMin: -0.5,
    presence_penaltyMax: 0.5,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -0.5,
    frequency_penaltyMax: 0.5,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.5,
    repeat_penaltyDefault: 1.2,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Gemma-2B-QuestionAnswering',
    modelName: 'gemma:2b',
    version: 'latest',
    description: 'Gemma 2B for focused question answering.',
    temperatureMin: 0,
    temperatureMax: 0.5,
    temperatureDefault: 0.3,
    top_pMin: 0,
    top_pMax: 0.5,
    top_pDefault: 0.4,
    top_kMin: 5,
    top_kMax: 50,
    top_kDefault: 20,
    max_tokensMin: 1,
    max_tokensMax: 1024,
    max_tokensDefault: 256,
    presence_penaltyMin: -1,
    presence_penaltyMax: 0,
    presence_penaltyDefault: -0.5,
    frequency_penaltyMin: -1,
    frequency_penaltyMax: 0,
    frequency_penaltyDefault: -0.5,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.5,
    repeat_penaltyDefault: 1.1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Llama3-Vision-Basic',
    modelName: 'llama3.2-vision:latest',
    version: 'latest',
    description: 'Llama 3.2 Vision with default settings.',
    temperatureMin: 0,
    temperatureMax: 1,
    temperatureDefault: 0.7,
    top_pMin: 0,
    top_pMax: 1,
    top_pDefault: 0.9,
    top_kMin: 0,
    top_kMax: 100,
    top_kDefault: 0,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 256,
    presence_penaltyMin: -2,
    presence_penaltyMax: 2,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -2,
    frequency_penaltyMax: 2,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 2,
    repeat_penaltyDefault: 1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Llama3-Vision-Deterministic',
    modelName: 'llama3.2-vision:latest',
    version: 'latest',
    description: 'Llama 3.2 Vision for more deterministic output.',
    temperatureMin: 0,
    temperatureMax: 0.2,
    temperatureDefault: 0.1,
    top_pMin: 0,
    top_pMax: 0.2,
    top_pDefault: 0.1,
    top_kMin: 0,
    top_kMax: 5,
    top_kDefault: 3,
    max_tokensMin: 1,
    max_tokensMax: 2048,
    max_tokensDefault: 512,
    presence_penaltyMin: -1,
    presence_penaltyMax: 1,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -1,
    frequency_penaltyMax: 1,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.2,
    repeat_penaltyDefault: 1.1,
    stop_sequences: [
      '<|file_separator|>',
      '<|file_separator|>',
      '<|end_of_turn|>',
    ],
    usageCount: 0,
  },
  {
    name: 'Llama3-Vision-Creative',
    modelName: 'llama3.2-vision:latest',
    version: 'latest',
    description: 'Llama 3.2 Vision for more creative output.',
    temperatureMin: 0.7,
    temperatureMax: 1,
    temperatureDefault: 0.8,
    top_pMin: 0.7,
    top_pMax: 1,
    top_pDefault: 0.95,
    top_kMin: 50,
    top_kMax: 100,
    top_kDefault: 75,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 1024,
    presence_penaltyMin: -0.5,
    presence_penaltyMax: 0.5,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -0.5,
    frequency_penaltyMax: 0.5,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.5,
    repeat_penaltyDefault: 1.2,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Qwen2-1.5B-Basic',
    modelName: 'qwen2:1.5b',
    version: 'latest',
    description: 'Qwen2 1.5B with default settings.',
    temperatureMin: 0,
    temperatureMax: 1,
    temperatureDefault: 0.7,
    top_pMin: 0,
    top_pMax: 1,
    top_pDefault: 0.9,
    top_kMin: 0,
    top_kMax: 100,
    top_kDefault: 0,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 256,
    presence_penaltyMin: -2,
    presence_penaltyMax: 2,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -2,
    frequency_penaltyMax: 2,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 2,
    repeat_penaltyDefault: 1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Qwen2-1.5B-Deterministic',
    modelName: 'qwen2:1.5b',
    version: 'latest',
    description: 'Qwen2 1.5B for more deterministic output.',
    temperatureMin: 0,
    temperatureMax: 0.2,
    temperatureDefault: 0.1,
    top_pMin: 0,
    top_pMax: 0.2,
    top_pDefault: 0.1,
    top_kMin: 0,
    top_kMax: 5,
    top_kDefault: 3,
    max_tokensMin: 1,
    max_tokensMax: 2048,
    max_tokensDefault: 512,
    presence_penaltyMin: -1,
    presence_penaltyMax: 1,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -1,
    frequency_penaltyMax: 1,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.2,
    repeat_penaltyDefault: 1.1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Qwen2-1.5B-Creative',
    modelName: 'qwen2:1.5b',
    version: 'latest',
    description: 'Qwen2 1.5B for more creative output.',
    temperatureMin: 0.7,
    temperatureMax: 1,
    temperatureDefault: 0.8,
    top_pMin: 0.7,
    top_pMax: 1,
    top_pDefault: 0.95,
    top_kMin: 50,
    top_kMax: 100,
    top_kDefault: 75,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 1024,
    presence_penaltyMin: -0.5,
    presence_penaltyMax: 0.5,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -0.5,
    frequency_penaltyMax: 0.5,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.5,
    repeat_penaltyDefault: 1.2,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'DeepSeek-1.5B-Basic',
    modelName: 'deepseek-r1:1.5b',
    version: 'latest',
    description: 'DeepSeek 1.5B with default settings.',
    temperatureMin: 0,
    temperatureMax: 1,
    temperatureDefault: 0.7,
    top_pMin: 0,
    top_pMax: 1,
    top_pDefault: 0.9,
    top_kMin: 0,
    top_kMax: 100,
    top_kDefault: 0,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 256,
    presence_penaltyMin: -2,
    presence_penaltyMax: 2,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -2,
    frequency_penaltyMax: 2,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 2,
    repeat_penaltyDefault: 1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'DeepSeek-1.5B-Deterministic',
    modelName: 'deepseek-r1:1.5b',
    version: 'latest',
    description: 'DeepSeek 1.5B for more deterministic output.',
    temperatureMin: 0,
    temperatureMax: 0.4,
    temperatureDefault: 0.2,
    top_pMin: 0,
    top_pMax: 0.4,
    top_pDefault: 0.3,
    top_kMin: 5,
    top_kMax: 20,
    top_kDefault: 10,
    max_tokensMin: 1,
    max_tokensMax: 2048,
    max_tokensDefault: 512,
    presence_penaltyMin: -0.5,
    presence_penaltyMax: 0.5,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -0.5,
    frequency_penaltyMax: 0.5,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.2,
    repeat_penaltyDefault: 1.1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'DeepSeek-1.5B-Creative',
    modelName: 'deepseek-r1:1.5b',
    version: 'latest',
    description: 'DeepSeek 1.5B for more creative output.',
    temperatureMin: 0.5,
    temperatureMax: 1,
    temperatureDefault: 0.7,
    top_pMin: 0.5,
    top_pMax: 1,
    top_pDefault: 0.8,
    top_kMin: 20,
    top_kMax: 100,
    top_kDefault: 50,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 1024,
    presence_penaltyMin: -0.2,
    presence_penaltyMax: 0.2,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -0.2,
    frequency_penaltyMax: 0.2,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.5,
    repeat_penaltyDefault: 1.2,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Llama3.2-Basic',
    modelName: 'llama3.2:latest',
    version: 'latest',
    description: 'Llama 3.2 with default settings.',
    temperatureMin: 0,
    temperatureMax: 1,
    temperatureDefault: 0.7,
    top_pMin: 0,
    top_pMax: 1,
    top_pDefault: 0.9,
    top_kMin: 0,
    top_kMax: 100,
    top_kDefault: 0,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 256,
    presence_penaltyMin: -2,
    presence_penaltyMax: 2,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -2,
    frequency_penaltyMax: 2,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 2,
    repeat_penaltyDefault: 1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Llama3.2-Deterministic',
    modelName: 'llama3.2:latest',
    version: 'latest',
    description: 'Llama 3.2 for more deterministic output.',
    temperatureMin: 0,
    temperatureMax: 0.2,
    temperatureDefault: 0.1,
    top_pMin: 0,
    top_pMax: 0.2,
    top_pDefault: 0.1,
    top_kMin: 0,
    top_kMax: 5,
    top_kDefault: 3,
    max_tokensMin: 1,
    max_tokensMax: 2048,
    max_tokensDefault: 512,
    presence_penaltyMin: -1,
    presence_penaltyMax: 1,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -1,
    frequency_penaltyMax: 1,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.2,
    repeat_penaltyDefault: 1.1,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
  {
    name: 'Llama3.2-Creative',
    modelName: 'llama3.2:latest',
    version: 'latest',
    description: 'Llama 3.2 for more creative output.',
    temperatureMin: 0.7,
    temperatureMax: 1,
    temperatureDefault: 0.8,
    top_pMin: 0.7,
    top_pMax: 1,
    top_pDefault: 0.95,
    top_kMin: 50,
    top_kMax: 100,
    top_kDefault: 75,
    max_tokensMin: 1,
    max_tokensMax: 4096,
    max_tokensDefault: 1024,
    presence_penaltyMin: -0.5,
    presence_penaltyMax: 0.5,
    presence_penaltyDefault: 0,
    frequency_penaltyMin: -0.5,
    frequency_penaltyMax: 0.5,
    frequency_penaltyDefault: 0,
    repeat_penaltyMin: 1,
    repeat_penaltyMax: 1.5,
    repeat_penaltyDefault: 1.2,
    stop_sequences: ['<|file_separator|>', '<|end_of_turn|>'],
    usageCount: 0,
  },
];
